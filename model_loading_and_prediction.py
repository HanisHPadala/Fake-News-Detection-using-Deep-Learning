# -*- coding: utf-8 -*-
"""model Loading  and prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gJqf2YYPwz7X7rGvzxdKdvREHQORoMT7
"""

import numpy as np
import re
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
import nltk
from nltk.corpus import stopwords

# Load stopwords
nltk.download('stopwords')
stop_words = set(stopwords.words("english"))

# Load the trained model and tokenizer
model = load_model("/content/fake_news_detection_model.keras")

# Set tokenizer parameters (must match those used during training)
MAX_NB_WORDS = 10000  # Vocabulary size used in training
MAX_SEQUENCE_LENGTH = 150  # Sequence length used in training

# Reload and configure tokenizer
tokenizer = Tokenizer(num_words=MAX_NB_WORDS)
# (Note: you must load and fit the tokenizer on your combined data texts if not saved separately)

# Define the text cleaning function
def clean_text(text):
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = text.lower()
    text = " ".join([word for word in text.split() if word not in stop_words])
    return text

# Define preprocessing function for input text
def preprocess_text(text, tokenizer, max_sequence_length):
    text = clean_text(text)
    sequence = tokenizer.texts_to_sequences([text])
    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length)
    return padded_sequence

# Predict function for manual input
def predict_news_type():
    input_text = input("Enter the news text to predict: ")
    processed_text = preprocess_text(input_text, tokenizer, MAX_SEQUENCE_LENGTH)
    prediction = model.predict(processed_text)

    if prediction > 0.5:
        print("The news is likely REAL.")
    else:
        print("The news is likely FAKE.")

# Run prediction
if __name__ == "__main__":
    predict_news_type()